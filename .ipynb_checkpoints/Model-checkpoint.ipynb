{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = keras.datasets.imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 100s 6us/step\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = data.load_data(num_words=10000)  \n",
    "# taking words that are 10000 frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set =  [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "Label =  [0 1 1 0 1 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print('Train Set = ',train_data[0])\n",
    "print('Label = ',test_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 9s 5us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = data.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {k: (v + 3) for k, v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2\n",
    "word_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefining train and test data that is trimming data\n",
    "# preprocessing of data\n",
    "\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
      "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
      "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
      "  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147\n",
      " 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16\n",
      "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
      "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
      " 5244   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
      "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
      "   52    5   14  407   16   82    2    8    4  107  117 5952   15  256\n",
      "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
      "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
      " 2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
      "   26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
      "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
      "  103   32   15   16 5345   19  178   32    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1  591  202   14   31    6  717   10   10    2    2    5    4  360\n",
      "    7    4  177 5760  394  354    4  123    9 1035 1035 1035   10   10\n",
      "   13   92  124   89  488 7944  100   28 1668   14   31   23   27 7479\n",
      "   29  220  468    8  124   14  286  170    8  157   46    5   27  239\n",
      "   16  179    2   38   32   25 7944  451  202   14    6  717    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print human readable review\n",
    "def decode_review(text): \n",
    "    return \" \".join([reverse_word_index.get(i, \"?\") for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script and great acting my words of wisdom for you are that you probably have no friends because you were in the movie you are probably wishing you had all that time back of your life that you wasted on making this movie br br there is no way that this is a serious movie there was an old guy that gets stabbed and it doesn't even hurt him at all and when everyone else gets stabbed they drop dead br br it was probably important that these people killed random people and ate them and also hung out with an 80 year old man that wanted to put the parts into his body br br my favorite part was when the old man found the or however you spell it because that made the movie seem very intellectual and probably helped to reach the older crowd br br what really blew my mind that they decided to throw in that random scene about the college girls going into the woods looking for fake <UNK> br br if you do attempt to see this movie you should probably fill up your <UNK> and drop your <UNK> in it and be ready to jump in br br this is a must see for anyone who believes there life could not get any worse because this will help you realize there are people out there the makers of this movie who are even more pathetic and are going no where in life\n"
     ]
    }
   ],
   "source": [
    "print(decode_review(test_data[13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 250\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data[0]),len(test_data[44]))  # having different len of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "# model is to tell which movie review is good or which is bad\n",
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Embedding(88000, 16)) # we are creating 10,000 vectors of each word of 16 dimensions\n",
    "model.add(keras.layers.GlobalAveragePooling1D()) # puts higher dimension data to lower dimension\n",
    "model.add(keras.layers.Dense(16, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          1408000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,408,289\n",
      "Trainable params: 1,408,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model defining\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting validation data to check the performance of model\n",
    "x_val =train_data[:10000]\n",
    "x_train = train_data[10000:]\n",
    "y_val =train_labels[:10000]\n",
    "y_train = train_labels[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "30/30 [==============================] - 2s 61ms/step - loss: 0.6920 - accuracy: 0.5543 - val_loss: 0.6905 - val_accuracy: 0.5157\n",
      "Epoch 2/40\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.6870 - accuracy: 0.5827 - val_loss: 0.6835 - val_accuracy: 0.7143\n",
      "Epoch 3/40\n",
      "30/30 [==============================] - 2s 52ms/step - loss: 0.6762 - accuracy: 0.7263 - val_loss: 0.6701 - val_accuracy: 0.7173\n",
      "Epoch 4/40\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.6571 - accuracy: 0.7491 - val_loss: 0.6483 - val_accuracy: 0.7519\n",
      "Epoch 5/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.6287 - accuracy: 0.7762 - val_loss: 0.6181 - val_accuracy: 0.7771\n",
      "Epoch 6/40\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.5918 - accuracy: 0.7955 - val_loss: 0.5816 - val_accuracy: 0.7949\n",
      "Epoch 7/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.5490 - accuracy: 0.8249 - val_loss: 0.5414 - val_accuracy: 0.8137\n",
      "Epoch 8/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.5037 - accuracy: 0.8377 - val_loss: 0.4994 - val_accuracy: 0.8275\n",
      "Epoch 9/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.4581 - accuracy: 0.8556 - val_loss: 0.4605 - val_accuracy: 0.8363\n",
      "Epoch 10/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.4169 - accuracy: 0.8676 - val_loss: 0.4269 - val_accuracy: 0.8457\n",
      "Epoch 11/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.3815 - accuracy: 0.8780 - val_loss: 0.3993 - val_accuracy: 0.8542\n",
      "Epoch 12/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.3513 - accuracy: 0.8853 - val_loss: 0.3767 - val_accuracy: 0.8595\n",
      "Epoch 13/40\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.3263 - accuracy: 0.8913 - val_loss: 0.3587 - val_accuracy: 0.8646\n",
      "Epoch 14/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.3047 - accuracy: 0.8975 - val_loss: 0.3447 - val_accuracy: 0.8700\n",
      "Epoch 15/40\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.2864 - accuracy: 0.9017 - val_loss: 0.3331 - val_accuracy: 0.8712\n",
      "Epoch 16/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.2704 - accuracy: 0.9068 - val_loss: 0.3266 - val_accuracy: 0.8698\n",
      "Epoch 17/40\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.2557 - accuracy: 0.9134 - val_loss: 0.3160 - val_accuracy: 0.8768\n",
      "Epoch 18/40\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.2428 - accuracy: 0.9171 - val_loss: 0.3094 - val_accuracy: 0.8781\n",
      "Epoch 19/40\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.2306 - accuracy: 0.9201 - val_loss: 0.3034 - val_accuracy: 0.8791\n",
      "Epoch 20/40\n",
      "30/30 [==============================] - 2s 52ms/step - loss: 0.2203 - accuracy: 0.9238 - val_loss: 0.2997 - val_accuracy: 0.8813\n",
      "Epoch 21/40\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.2105 - accuracy: 0.9268 - val_loss: 0.2949 - val_accuracy: 0.8828\n",
      "Epoch 22/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.2009 - accuracy: 0.9321 - val_loss: 0.2921 - val_accuracy: 0.8828\n",
      "Epoch 23/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.1924 - accuracy: 0.9347 - val_loss: 0.2897 - val_accuracy: 0.8831\n",
      "Epoch 24/40\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.1845 - accuracy: 0.9381 - val_loss: 0.2882 - val_accuracy: 0.8849\n",
      "Epoch 25/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.1767 - accuracy: 0.9434 - val_loss: 0.2869 - val_accuracy: 0.8849\n",
      "Epoch 26/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.1697 - accuracy: 0.9454 - val_loss: 0.2858 - val_accuracy: 0.8858\n",
      "Epoch 27/40\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.1628 - accuracy: 0.9483 - val_loss: 0.2855 - val_accuracy: 0.8862\n",
      "Epoch 28/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.1567 - accuracy: 0.9506 - val_loss: 0.2856 - val_accuracy: 0.8853\n",
      "Epoch 29/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.1503 - accuracy: 0.9535 - val_loss: 0.2865 - val_accuracy: 0.8847\n",
      "Epoch 30/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.1447 - accuracy: 0.9561 - val_loss: 0.2870 - val_accuracy: 0.8861\n",
      "Epoch 31/40\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.1391 - accuracy: 0.9574 - val_loss: 0.2873 - val_accuracy: 0.8867\n",
      "Epoch 32/40\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.1345 - accuracy: 0.9593 - val_loss: 0.2891 - val_accuracy: 0.8862\n",
      "Epoch 33/40\n",
      "30/30 [==============================] - 2s 55ms/step - loss: 0.1293 - accuracy: 0.9626 - val_loss: 0.2901 - val_accuracy: 0.8862\n",
      "Epoch 34/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.1240 - accuracy: 0.9637 - val_loss: 0.2912 - val_accuracy: 0.8863\n",
      "Epoch 35/40\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.1193 - accuracy: 0.9653 - val_loss: 0.2946 - val_accuracy: 0.8847\n",
      "Epoch 36/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.1150 - accuracy: 0.9675 - val_loss: 0.2950 - val_accuracy: 0.8856\n",
      "Epoch 37/40\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.1109 - accuracy: 0.9681 - val_loss: 0.2977 - val_accuracy: 0.8852\n",
      "Epoch 38/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.1066 - accuracy: 0.9707 - val_loss: 0.3008 - val_accuracy: 0.8843\n",
      "Epoch 39/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.1027 - accuracy: 0.9727 - val_loss: 0.3034 - val_accuracy: 0.8832\n",
      "Epoch 40/40\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.0991 - accuracy: 0.9742 - val_loss: 0.3049 - val_accuracy: 0.8833\n"
     ]
    }
   ],
   "source": [
    "fitModel = model.fit(x_train, y_train, epochs = 40, batch_size = 512 , validation_data = (x_val, y_val), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 2ms/step - loss: 0.3256 - accuracy: 0.8715\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss =  0.32562515139579773 \n",
      " Accuracy = 0.8714799880981445\n"
     ]
    }
   ],
   "source": [
    "print(' Loss = ',results[0],'\\n','Accuracy =', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving data\n",
    "model.save(\"Moview_review_Model_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: \n",
      "<START> please give this one a miss br br <UNK> <UNK> and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite <UNK> so all you madison fans give this a miss <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Prediction: [2.370283e-17]\n",
      "Actual: 0\n",
      "[0.32562515139579773, 0.8714799880981445]\n",
      "Review: \n",
      "focuses on mood and character development the plot is very simple and many of the scenes take place on the same set in frances <UNK> the sandy dennis character apartment but the film builds to a disturbing climax br br the characters create an atmosphere <UNK> with sexual tension and psychological <UNK> it's very interesting that robert altman directed this considering the style and structure of his other films still the trademark altman audio style is evident here and there i think what really makes this film work is the brilliant performance by sandy dennis it's definitely one of her darker characters but she plays it so perfectly and convincingly that it's scary michael burns does a good job as the mute young man regular altman player michael murphy has a small part the <UNK> moody set fits the content of the story very well in short this movie is a powerful study of loneliness sexual <UNK> and desperation be patient <UNK> up the atmosphere and pay attention to the wonderfully written script br br i praise robert altman this is one of his many films that deals with unconventional fascinating subject matter this film is disturbing but it's sincere and it's sure to <UNK> a strong emotional response from the viewer if you want to see an unusual film some might even say bizarre this is worth the time br br unfortunately it's very difficult to find in video stores you may have to buy it off the internet\n",
      "Prediction: [0.00070989]\n",
      "Actual: 1\n",
      "[0.32562515139579773, 0.8714799880981445]\n"
     ]
    }
   ],
   "source": [
    "# making sense of model\n",
    "for i in range(2):\n",
    "    test_review = test_data[i]\n",
    "    predict = model.predict([test_review])\n",
    "    print(\"Review: \")\n",
    "    print(decode_review(test_review))\n",
    "    print(\"Prediction: \" + str(predict[i]))\n",
    "    print(\"Actual: \" + str(test_labels[i]))\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Model\n",
    "model = keras.models.load_model(\"Moview_review_Model_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_encode(s):\n",
    "    encoded = [1]\n",
    "\n",
    "    for word in s:\n",
    "        if word.lower() in word_index:\n",
    "            encoded.append(word_index[word.lower()])\n",
    "        else:\n",
    "            encoded.append(2)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95318717]\n"
     ]
    }
   ],
   "source": [
    "with open(\"avenger.txt\", encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        nline = line.replace(\",\", \"\").replace(\".\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\":\", \"\").replace(\"\\\"\",\"\").strip().split(\" \")\n",
    "        encode = review_encode(nline)\n",
    "        encode = keras.preprocessing.sequence.pad_sequences([encode], value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)\n",
    "        predict = model.predict(encode)\n",
    "        #print(line)\n",
    "        #print(encode)\n",
    "        print(predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13804397]\n"
     ]
    }
   ],
   "source": [
    "# bad movie review\n",
    "with open(\"bad.txt\", encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        nline = line.replace(\",\",\"\").replace(\".\",\"\").replace(\"(\",\"\").replace(\")\",\"\").replace(\":\",\"\").replace(\"\\\"\",\"\").strip().split(\" \")\n",
    "        encode = review_encode(nline)\n",
    "        encode = keras.preprocessing.sequence.pad_sequences([encode], value= word_index[\"<PAD>\"], padding = \"post\", maxlen = 250)\n",
    "        predict = model.predict(encode)\n",
    "        #print(line)\n",
    "        #print(encode)\n",
    "        print(predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54399586]\n"
     ]
    }
   ],
   "source": [
    "with open(\"Dil-Bechara-5-10.txt\", encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        nline = line.replace(\",\",\"\").replace(\".\",\"\").replace(\"(\",\"\").replace(\")\",\"\").replace(\":\",\"\").replace(\"\\\"\",\"\").strip().split(\" \")\n",
    "        encode = review_encode(nline)\n",
    "        encode = keras.preprocessing.sequence.pad_sequences([encode], value= word_index[\"<PAD>\"], padding = \"post\", maxlen = 250)\n",
    "        predict = model.predict(encode)\n",
    "        #print(line)\n",
    "        #print(encode)\n",
    "        print(predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9871561]\n"
     ]
    }
   ],
   "source": [
    "with open(\"Dil-Bechara-10-10.txt\", encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        nline = line.replace(\",\",\"\").replace(\".\",\"\").replace(\"(\",\"\").replace(\")\",\"\").replace(\":\",\"\").replace(\"\\\"\",\"\").strip().split(\" \")\n",
    "        encode = review_encode(nline)\n",
    "        encode = keras.preprocessing.sequence.pad_sequences([encode], value= word_index[\"<PAD>\"], padding = \"post\", maxlen = 250)\n",
    "        predict = model.predict(encode)\n",
    "        #print(line)\n",
    "        #print(encode)\n",
    "        print(predict[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
